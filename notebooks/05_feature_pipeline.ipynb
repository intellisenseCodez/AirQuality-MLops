{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline with Feature Store\n",
    "\n",
    "## Overview\n",
    "In this project i made use of Hopsworks feature store. Hopsworks and its Feature Store are an open source data-intensive AI platform used for the development and operation of machine learning models at scale. The Hopsworks Feature Store provides the HSFS API \n",
    "\n",
    "- to enable clients to write features to feature groups in the feature store, \n",
    "- and to read features from feature views \n",
    "\n",
    "![The Hopsworks Architecture!](../images/fs_architecture.jpg \"The Hopsworks Architecture\")\n",
    "\n",
    "## Feature Pipelines\n",
    "The Feature Pipeline is the foundation of the FTI architecture. It is responsible for transforming raw data into engineered features that are ready for both training and inference. This involves:\n",
    "\n",
    "- **Data Extraction**: Retrieving raw data from various sources, such as relational databases, APIs, or data lakes. This part can be separated from the Feature Pipeline.\n",
    "- **Feature Engineering**: Performing transformations like aggregations, scaling, encoding, and computing derived metrics.\n",
    "- **Feature Storage**: Saving the processed features in a feature store (e.g., Feast, Hopsworks) for reuse during training and inference.\n",
    "\n",
    "\n",
    "![The ETL Architecture!](../images/ETL_architecture.png \"The ETL Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import hopsworks\n",
    "from confluent_kafka import Producer\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "from paths import  TRANSFORMED_DATA_DIR\n",
    "\n",
    "\n",
    "# load environment\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "HOPSWORK_LOGIN_API_KEY = os.getenv(\"HOPSWORK_LOGIN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hopsworks version\n",
    "hopsworks.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 00:29:31,473 INFO: Closing external client and cleaning up certificates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "2025-03-09 00:29:31,557 INFO: Initializing external client\n",
      "2025-03-09 00:29:31,558 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-09 00:29:36,823 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214615\n"
     ]
    }
   ],
   "source": [
    "# Login to the Hopsworks feature store\n",
    "connection = hopsworks.login(\n",
    "    host='c.app.hopsworks.ai',                 # DNS of your Feature Store instance\n",
    "    port=443,  \n",
    "    project='air_quality_project', \n",
    "    engine=\"python\",\n",
    "    api_key_value=HOPSWORK_LOGIN_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully Connected to air_quality_project\n"
     ]
    }
   ],
   "source": [
    "# connect to feature store\n",
    "project_name = \"air_quality_project\"\n",
    "\n",
    "try:\n",
    "    feature_store = connection.get_feature_store(name=project_name)\n",
    "    print(f\"✅ Successfully Connected to {feature_store.project_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Feature store not available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or Create a feature group\n",
    "\n",
    "fg = feature_store.get_or_create_feature_group(\n",
    "    name=\"air_quality_historical_data_2020_to_2025\",\n",
    "    version=1,\n",
    "    description=\"Historical Data of Air Quality in Lagos\",\n",
    "    primary_key=['row_id'],\n",
    "    event_time='timestamp',\n",
    "    online_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>aqi_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1682.28</td>\n",
       "      <td>0.13</td>\n",
       "      <td>18.85</td>\n",
       "      <td>12.88</td>\n",
       "      <td>8.82</td>\n",
       "      <td>64.62</td>\n",
       "      <td>90.85</td>\n",
       "      <td>17.48</td>\n",
       "      <td>2020-11-25 01:00:00</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>Very Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2109.53</td>\n",
       "      <td>0.36</td>\n",
       "      <td>21.94</td>\n",
       "      <td>9.30</td>\n",
       "      <td>10.37</td>\n",
       "      <td>93.95</td>\n",
       "      <td>127.43</td>\n",
       "      <td>21.03</td>\n",
       "      <td>2020-11-25 02:00:00</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>Very Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2750.40</td>\n",
       "      <td>1.41</td>\n",
       "      <td>26.39</td>\n",
       "      <td>4.16</td>\n",
       "      <td>12.52</td>\n",
       "      <td>136.28</td>\n",
       "      <td>181.39</td>\n",
       "      <td>25.59</td>\n",
       "      <td>2020-11-25 03:00:00</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Very Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3337.86</td>\n",
       "      <td>4.81</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>14.07</td>\n",
       "      <td>175.09</td>\n",
       "      <td>233.20</td>\n",
       "      <td>28.63</td>\n",
       "      <td>2020-11-25 04:00:00</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>Very Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3738.40</td>\n",
       "      <td>10.95</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.26</td>\n",
       "      <td>200.27</td>\n",
       "      <td>262.51</td>\n",
       "      <td>30.91</td>\n",
       "      <td>2020-11-25 05:00:00</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>Very Poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  aqi       co     no    no2     o3    so2   pm2_5    pm10    nh3  \\\n",
       "0       0    5  1682.28   0.13  18.85  12.88   8.82   64.62   90.85  17.48   \n",
       "1       1    5  2109.53   0.36  21.94   9.30  10.37   93.95  127.43  21.03   \n",
       "2       2    5  2750.40   1.41  26.39   4.16  12.52  136.28  181.39  25.59   \n",
       "3       3    5  3337.86   4.81  28.45   0.78  14.07  175.09  233.20  28.63   \n",
       "4       4    5  3738.40  10.95  28.45   0.10  15.26  200.27  262.51  30.91   \n",
       "\n",
       "             timestamp        date      time  aqi_range  \n",
       "0  2020-11-25 01:00:00  2020-11-25  01:00:00  Very Poor  \n",
       "1  2020-11-25 02:00:00  2020-11-25  02:00:00  Very Poor  \n",
       "2  2020-11-25 03:00:00  2020-11-25  03:00:00  Very Poor  \n",
       "3  2020-11-25 04:00:00  2020-11-25  04:00:00  Very Poor  \n",
       "4  2020-11-25 05:00:00  2020-11-25  05:00:00  Very Poor  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe\n",
    "df = pd.read_csv(f\"{TRANSFORMED_DATA_DIR}/weather_20200101_to_20250201.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36311 entries, 0 to 36310\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   row_id     36311 non-null  int64  \n",
      " 1   aqi        36311 non-null  int64  \n",
      " 2   co         36311 non-null  float64\n",
      " 3   no         36311 non-null  float64\n",
      " 4   no2        36311 non-null  float64\n",
      " 5   o3         36311 non-null  float64\n",
      " 6   so2        36311 non-null  float64\n",
      " 7   pm2_5      36311 non-null  float64\n",
      " 8   pm10       36311 non-null  float64\n",
      " 9   nh3        36311 non-null  float64\n",
      " 10  timestamp  36311 non-null  object \n",
      " 11  date       36311 non-null  object \n",
      " 12  time       36311 non-null  object \n",
      " 13  aqi_range  36311 non-null  object \n",
      "dtypes: float64(8), int64(2), object(4)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp column to datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert 'time' column to time format\n",
    "df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214615/fs/1202247/fg/1403746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 36311/36311 | Elapsed Time: 00:26 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_historical_data_2020_to_2025_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214615/jobs/named/air_quality_historical_data_2020_to_2025_1_offline_fg_materialization/executions\n",
      "Upload time 50.216068983078 seconds ---\n",
      "✅ Done!\n"
     ]
    }
   ],
   "source": [
    "# save dataframe into feature group\n",
    "start_time = time.time()\n",
    "\n",
    "try:   \n",
    "    fg.save(df, write_options={\"wait_for_job\": False})\n",
    "except Exception as err:\n",
    "    print(f\"Feature group {fg.name} already exists! or Error encountered\")\n",
    "    raise err\n",
    "\n",
    "print(\"Upload time %s seconds ---\" % (time.time() - start_time))\n",
    "print('✅ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214615/featurestores/1202247/featuregroups/1403746). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"errorCode\":120003,\"usrMsg\":\"Transaction marked for rollback.\",\"errorMsg\":\"The last transaction did not complete as expected\"}', error code: 120003, error msg: The last transaction did not complete as expected, user msg: Transaction marked for rollback.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestAPIError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      2\u001b[39m feature_descriptions = [\n\u001b[32m      3\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrow_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mUnique identifier for each record.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m      4\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33maqi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mAir Quality Index (AQI) value indicating the pollution level.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33maqi_range\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCategorical label describing the AQI level.\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     17\u001b[39m ]\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m feature_descriptions: \n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_feature_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/feature_group.py:976\u001b[39m, in \u001b[36mFeatureGroupBase.update_feature_description\u001b[39m\u001b[34m(self, feature_name, description)\u001b[39m\n\u001b[32m    974\u001b[39m f_copy = copy.deepcopy(\u001b[38;5;28mself\u001b[39m[feature_name])\n\u001b[32m    975\u001b[39m f_copy.description = description\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mf_copy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:324\u001b[39m, in \u001b[36mFeatureGroupEngine.update_features\u001b[39m\u001b[34m(self, feature_group, updated_features)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_group, updated_features):\n\u001b[32m    323\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Updates features safely.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_features_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_feature_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:318\u001b[39m, in \u001b[36mFeatureGroupEngine._update_features_metadata\u001b[39m\u001b[34m(self, feature_group, features)\u001b[39m\n\u001b[32m    316\u001b[39m copy_feature_group = fg.FeatureGroup.from_response_json(feature_group.to_dict())\n\u001b[32m    317\u001b[39m copy_feature_group.features = features\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_feature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdateMetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/core/feature_group_api.py:308\u001b[39m, in \u001b[36mFeatureGroupApi.update_metadata\u001b[39m\u001b[34m(self, feature_group_instance, feature_group_copy, query_parameter, query_parameter_value)\u001b[39m\n\u001b[32m    305\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    306\u001b[39m query_params = {query_parameter: query_parameter_value}\n\u001b[32m    307\u001b[39m feature_group_object = feature_group_instance.update_from_response_json(\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_group_copy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    315\u001b[39m )\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hopsworks_common/decorators.py:45\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hopsworks_common/client/base.py:186\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code // \u001b[32m100\u001b[39m != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.RestAPIError(url, response)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mRestAPIError\u001b[39m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214615/featurestores/1202247/featuregroups/1403746). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"errorCode\":120003,\"usrMsg\":\"Transaction marked for rollback.\",\"errorMsg\":\"The last transaction did not complete as expected\"}', error code: 120003, error msg: The last transaction did not complete as expected, user msg: Transaction marked for rollback."
     ]
    }
   ],
   "source": [
    "# updates the feature description\n",
    "feature_descriptions = [\n",
    "    {\"name\": \"row_id\", \"description\": \"Unique identifier for each record.\"},\n",
    "    {\"name\": \"aqi\", \"description\": \"Air Quality Index (AQI) value indicating the pollution level.\"},\n",
    "    {\"name\": \"co\", \"description\": \"Carbon Monoxide (CO) concentration in µg/m³.\"},\n",
    "    {\"name\": \"no\", \"description\": \"Nitric Oxide (NO) concentration in µg/m³.\"},\n",
    "    {\"name\": \"no2\", \"description\": \"Nitrogen Dioxide (NO₂) concentration in µg/m³.\"},\n",
    "    {\"name\": \"o3\", \"description\": \"Ozone (O₃) concentration in µg/m³.\"},\n",
    "    {\"name\": \"so2\", \"description\": \"Sulfur Dioxide (SO₂) concentration in µg/m³.\"},\n",
    "    {\"name\": \"pm2_5\", \"description\": \"Fine Particulate Matter (PM2.5) concentration in µg/m³.\"},\n",
    "    {\"name\": \"pm10\", \"description\": \"Coarse Particulate Matter (PM10) concentration in µg/m³.\"},\n",
    "    {\"name\": \"nh3\", \"description\": \"Ammonia (NH₃) concentration in µg/m³.\"},\n",
    "    {\"name\": \"timestamp\", \"description\": \"timestamp\"},\n",
    "    {\"name\": \"date\", \"description\": \"The date of the recorded measurement (YYYY-MM-DD).\"},\n",
    "    {\"name\": \"time\", \"description\": \"The time of the recorded measurement (HH:MM:SS).\"},\n",
    "    {\"aqi_bucket\": \"timestamp\", \"description\": \"Categorical label describing the AQI level.\"}\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature View\n",
    "\n",
    "A feature view is a logical view over (or interface to) a set of features that may come from different feature groups. You create a feature view by joining together features from existing feature groups. \n",
    "\n",
    "Feature views can include:\n",
    "\n",
    "- the label for the supervised ML problem\n",
    "- transformation functions that should be applied to specified features consistently between training and serving\n",
    "- the ability to create training data\n",
    "- the ability to retrieve a feature vector with the most recent feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214615/fs/1202247/fv/air_quality_view/version/1\n"
     ]
    }
   ],
   "source": [
    "# This feature view only uses on feature group, so the query is trivial\n",
    "\n",
    "# select all features except row_id, timestamp, date, time, aqi\n",
    "query = fg.select_except([\"row_id\",\"timestamp\",\"date\",\"time\", \"aqi\"])\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # create feature view if it doesn't exist yet\n",
    "    feature_view = feature_store.create_feature_view(\n",
    "        name='air_quality_view',\n",
    "        descriprion=\"Features from Air Quality Data\",\n",
    "        labels=[\"aqi_bucket\"],\n",
    "        query=query,\n",
    "    )\n",
    "except:\n",
    "    print('Feature view already existed. Skip creation.')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No version provided for getting feature view `air_quality_view`, defaulting to `1`.\n"
     ]
    }
   ],
   "source": [
    "# get feature view\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"air_quality_view\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
