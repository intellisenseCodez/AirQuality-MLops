{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline with Feature Store\n",
    "\n",
    "## Overview\n",
    "In this project i made use of Hopsworks feature store. Hopsworks and its Feature Store are an open source data-intensive AI platform used for the development and operation of machine learning models at scale. The Hopsworks Feature Store provides the HSFS API \n",
    "\n",
    "- to enable clients to write features to feature groups in the feature store, \n",
    "- and to read features from feature views \n",
    "\n",
    "![The Hopsworks Architecture!](../images/fs_architecture.jpg \"The Hopsworks Architecture\")\n",
    "\n",
    "## Feature Pipelines\n",
    "The Feature Pipeline is the foundation of the FTI architecture. It is responsible for transforming raw data into engineered features that are ready for both training and inference. This involves:\n",
    "\n",
    "- **Data Extraction**: Retrieving raw data from various sources, such as relational databases, APIs, or data lakes. This part can be separated from the Feature Pipeline.\n",
    "- **Feature Engineering**: Performing transformations like aggregations, scaling, encoding, and computing derived metrics.\n",
    "- **Feature Storage**: Saving the processed features in a feature store (e.g., Feast, Hopsworks) for reuse during training and inference.\n",
    "\n",
    "\n",
    "![The ETL Architecture!](../images/ETL_architecture.png \"The ETL Architecture\")\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Run in either \"Backfill\" or \"Normal\" operation.\n",
    "\n",
    "2. IF BACKFILL==True, we will load our DataFrame with data from the iris.csv file\n",
    "\n",
    "3. ELSE BACKFILL==False, we will load a DataFrame with new air data from API\n",
    "\n",
    "4. Write our DataFrame to a Feature Grou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import hopsworks\n",
    "from confluent_kafka import Producer\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parent / \"src\"))\n",
    "\n",
    "from paths import  TRANSFORMED_DATA_DIR\n",
    "from components.extract_air_data_api import *\n",
    "\n",
    "\n",
    "# load environment\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "HOPSWORK_LOGIN_API_KEY = os.getenv(\"HOPSWORK_LOGIN_API_KEY\")\n",
    "BACKFILL= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.8'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hopsworks version\n",
    "hopsworks.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backfill or create new input data\n",
    "you can run this pipeline in either backfill or new-data mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>aqi_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>460.63</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.56</td>\n",
       "      <td>33.62</td>\n",
       "      <td>1.45</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.63</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2025-03-10 12:57:02</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>12:57:02</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aqi      co    no   no2     o3   so2  pm2_5   pm10   nh3  \\\n",
       "0    1  460.63  0.36  1.56  33.62  1.45    5.6  15.63  4.18   \n",
       "\n",
       "            timestamp        date      time aqi_bucket  \n",
       "0 2025-03-10 12:57:02  2025-03-10  12:57:02       Good  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe\n",
    "if BACKFILL == True:\n",
    "    df = pd.read_csv(f\"{TRANSFORMED_DATA_DIR}/weather_20200101_to_20250201.csv\")\n",
    "    # Convert timestamp column to datetime\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    # Convert 'date' column to datetime format\n",
    "    df['date'] = df[\"timestamp\"].dt.date\n",
    "    \n",
    "    # Convert 'time' column to time format\n",
    "    df['time'] = df[\"timestamp\"].dt.time\n",
    "    df['time'] = df['time'].astype(str)\n",
    "else:\n",
    "    df = extract_and_load_current_air_pollution_data()\n",
    "    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   aqi         1 non-null      int64         \n",
      " 1   co          1 non-null      float64       \n",
      " 2   no          1 non-null      float64       \n",
      " 3   no2         1 non-null      float64       \n",
      " 4   o3          1 non-null      float64       \n",
      " 5   so2         1 non-null      float64       \n",
      " 6   pm2_5       1 non-null      float64       \n",
      " 7   pm10        1 non-null      float64       \n",
      " 8   nh3         1 non-null      float64       \n",
      " 9   timestamp   1 non-null      datetime64[ns]\n",
      " 10  date        1 non-null      object        \n",
      " 11  time        1 non-null      object        \n",
      " 12  aqi_bucket  1 non-null      object        \n",
      "dtypes: datetime64[ns](1), float64(8), int64(1), object(3)\n",
      "memory usage: 236.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate with Hopsworks using your API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-10 13:57:07,729 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-10 13:57:07,817 INFO: Initializing external client\n",
      "2025-03-10 13:57:07,820 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-10 13:57:10,687 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214615\n"
     ]
    }
   ],
   "source": [
    "# Login to the Hopsworks feature store\n",
    "connection = hopsworks.login(\n",
    "    host='c.app.hopsworks.ai',                 # DNS of your Feature Store instance\n",
    "    port=443,  \n",
    "    project='air_quality_project', \n",
    "    engine=\"python\",\n",
    "    api_key_value=HOPSWORK_LOGIN_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully Connected to air_quality_project\n"
     ]
    }
   ],
   "source": [
    "# connect to feature store\n",
    "project_name = \"air_quality_project\"\n",
    "\n",
    "try:\n",
    "    feature_store = connection.get_feature_store(name=project_name)\n",
    "    print(f\"✅ Successfully Connected to {feature_store.project_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Feature store not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and write to a feature group - primary keys\n",
    "\n",
    "To prevent duplicate entries, Hopsworks requires that each DataFame has a primary_key. \n",
    "A primary_key is one or more columns that uniquely identify the row. Here, we assume that each Iris flower has a unique combination of (\"date\", \"time\") feature values.\n",
    "\n",
    "The feature group will create its online schema using the schema of the Pandas DataFame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or Create a feature group\n",
    "\n",
    "fg = feature_store.get_or_create_feature_group(\n",
    "    name=\"air_quality_historical_data_2020_to_2025\",\n",
    "    version=1,\n",
    "    description=\"Historical Data of Air Quality in Lagos\",\n",
    "    primary_key=['date', 'time'],\n",
    "    event_time='timestamp',\n",
    "    online_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload time 15.722429037094116 seconds ---\n",
      "✅ Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1214615/jobs/named/air_quality_historical_data_2020_to_2025_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/air_quality_project/Resources/jobs/air_quality_historical_data_2020_to_2025_1_offline_fg_materialization/config_1741611083080) to trigger the materialization job again.\n"
     ]
    }
   ],
   "source": [
    "# save dataframe into feature group\n",
    "start_time = time.time()\n",
    "\n",
    "try:   \n",
    "    fg.insert(df, write_options={\"wait_for_job\": False})\n",
    "except Exception as err:\n",
    "    print(f\"Feature group {fg.name} already exists! or Error encountered\")\n",
    "    raise err\n",
    "\n",
    "print(\"Upload time %s seconds ---\" % (time.time() - start_time))\n",
    "print('✅ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aqi', 'co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3',\n",
       "       'timestamp', 'date', 'time', 'aqi_bucket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214615/featurestores/1202247/featuregroups/1403822). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"errorCode\":120003,\"usrMsg\":\"Transaction marked for rollback.\",\"errorMsg\":\"The last transaction did not complete as expected\"}', error code: 120003, error msg: The last transaction did not complete as expected, user msg: Transaction marked for rollback.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestAPIError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      2\u001b[39m feature_descriptions = [\n\u001b[32m      3\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33maqi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mAir Quality Index (AQI) value indicating the pollution level.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m      4\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mco\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCarbon Monoxide (CO) concentration in µg/m³.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33maqi_bucket\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCategorical label describing the AQI level.\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m feature_descriptions: \n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_feature_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/feature_group.py:976\u001b[39m, in \u001b[36mFeatureGroupBase.update_feature_description\u001b[39m\u001b[34m(self, feature_name, description)\u001b[39m\n\u001b[32m    974\u001b[39m f_copy = copy.deepcopy(\u001b[38;5;28mself\u001b[39m[feature_name])\n\u001b[32m    975\u001b[39m f_copy.description = description\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mf_copy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:324\u001b[39m, in \u001b[36mFeatureGroupEngine.update_features\u001b[39m\u001b[34m(self, feature_group, updated_features)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_group, updated_features):\n\u001b[32m    323\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Updates features safely.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_features_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_feature_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:318\u001b[39m, in \u001b[36mFeatureGroupEngine._update_features_metadata\u001b[39m\u001b[34m(self, feature_group, features)\u001b[39m\n\u001b[32m    316\u001b[39m copy_feature_group = fg.FeatureGroup.from_response_json(feature_group.to_dict())\n\u001b[32m    317\u001b[39m copy_feature_group.features = features\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_feature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdateMetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hsfs/core/feature_group_api.py:308\u001b[39m, in \u001b[36mFeatureGroupApi.update_metadata\u001b[39m\u001b[34m(self, feature_group_instance, feature_group_copy, query_parameter, query_parameter_value)\u001b[39m\n\u001b[32m    305\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    306\u001b[39m query_params = {query_parameter: query_parameter_value}\n\u001b[32m    307\u001b[39m feature_group_object = feature_group_instance.update_from_response_json(\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_group_copy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    315\u001b[39m )\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_group_object\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hopsworks_common/decorators.py:45\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/horlarDEV/Air_MLOPs/venv/lib/python3.11/site-packages/hopsworks_common/client/base.py:186\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code // \u001b[32m100\u001b[39m != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.RestAPIError(url, response)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mRestAPIError\u001b[39m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1214615/featurestores/1202247/featuregroups/1403822). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"errorCode\":120003,\"usrMsg\":\"Transaction marked for rollback.\",\"errorMsg\":\"The last transaction did not complete as expected\"}', error code: 120003, error msg: The last transaction did not complete as expected, user msg: Transaction marked for rollback."
     ]
    }
   ],
   "source": [
    "# updates the feature description\n",
    "feature_descriptions = [\n",
    "    {\"name\": \"aqi\", \"description\": \"Air Quality Index (AQI) value indicating the pollution level.\"},\n",
    "    {\"name\": \"co\", \"description\": \"Carbon Monoxide (CO) concentration in µg/m³.\"},\n",
    "    {\"name\": \"no\", \"description\": \"Nitric Oxide (NO) concentration in µg/m³.\"},\n",
    "    {\"name\": \"no2\", \"description\": \"Nitrogen Dioxide (NO₂) concentration in µg/m³.\"},\n",
    "    {\"name\": \"o3\", \"description\": \"Ozone (O₃) concentration in µg/m³.\"},\n",
    "    {\"name\": \"so2\", \"description\": \"Sulfur Dioxide (SO₂) concentration in µg/m³.\"},\n",
    "    {\"name\": \"pm2_5\", \"description\": \"Fine Particulate Matter (PM2.5) concentration in µg/m³.\"},\n",
    "    {\"name\": \"pm10\", \"description\": \"Coarse Particulate Matter (PM10) concentration in µg/m³.\"},\n",
    "    {\"name\": \"nh3\", \"description\": \"Ammonia (NH₃) concentration in µg/m³.\"},\n",
    "    {\"name\": \"timestamp\", \"description\": \"timestamp\"},\n",
    "    {\"name\": \"date\", \"description\": \"The date of the recorded measurement (YYYY-MM-DD).\"},\n",
    "    {\"name\": \"time\", \"description\": \"The time of the recorded measurement (HH:MM:SS).\"},\n",
    "    {\"aqi_bucket\": \"timestamp\", \"description\": \"Categorical label describing the AQI level.\"}\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
